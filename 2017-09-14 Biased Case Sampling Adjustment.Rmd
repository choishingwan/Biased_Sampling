---
title: "Biased Case Sampling Adjustment"
csl: nature.csl
output:
  pdf_document:
    toc: yes
  html_notebook:
    toc: yes
    toc_float: yes
  html_document:
    toc: yes
    toc_float: yes
bibliography: citations.bib
---
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { 
      equationNumbers: { 
            autoNumber: "all",
            formatNumber: function (n) {return n}
      } 
  }
});
</script>

# Abstract
- Polygenic Risk score important
- Most often defined using $R^2$
- Previous study has provide a nice adjustment for $R^2$ for case control ascertainment bias
- However, they assume a random sampling of case and control in the population
- In reality, cases are usually biased in their sampling. i.e in biobank settings, samples tends to be more healthy
- Therefore there is a need for $R^2$ adjustment that are robust towards biased sampling of cases
- Here we provide this method which "works?"

# Introduction

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(cache=TRUE)
library(ggplot2)
library(grid)
library(plyr)
library(RColorBrewer)
library(truncnorm)
library(dplyr)
library(reshape2)
library(compiler)
setCompilerOptions(optimize=3)
```
One of the main output from the polygenic risk score analysis is the coefficient of determination ($R^2$), which quantifies the portion of phenotypic variance explained by the polygenic risk score ($S$). 
However, due to difficulties in defining the residual variance for binary traits, pseudo-$R^2$, usually the Nagelkerke $R^2$, is use, which suffers from ascertainment bias[@lee_better_2012].
Lee et al(2012)[@lee_better_2012] proposed a better coefficient of determination by adjusting the Nagelkerke $R^2$ according to the population prevalence ($K$) of the trait and the case control ratio included in the study.

# Methodology
The liability threshold model[@falconer_inheritance_1965] assumes that the "liability of a disease ($P$) follows a standard normal distribution with mean ($\mu$) 0  and variance ($\sigma^2$) 1 and is composes of the additive genetic factor ($G$) and the environmental factors ($E$), each sampled from an independent normal distribution.
For a trait with heritability of $h^2$, the model can be defined as:
\begin{align}
    P &\sim N(\mu_p=0, \sigma^2_p=1)\notag \\
    G &\sim N(\mu_g=0, \sigma^2_g=h^2)\notag \\
    E &\sim N(\mu_e=0, \sigma^2_e=(1-h^2))\notag \\
    P &= G+E\notag
\end{align}

Similarly, the disease liability can be expressed as the sum of a polygenic risk score ($S$) and an error term ($\epsilon$), where the polygenic risk score follows a normal distribution with mean $\mu_s$ and variance $\sigma^2_s$:
\begin{align}
S &\sim N(\mu_s, \sigma^2_s)\notag \\
P &= S+\epsilon\notag
\end{align}

The coefficient of determination $\rho^2$ can then be defined as 
\begin{align}
\rho^2 &=\frac{\sigma^2_s}{\sigma^2_p}\notag \\
\because \sigma^2_p&=1\notag \\
\therefore \rho^2 &= \sigma^2_s\notag
\end{align}

## Mean and Variance of Disease Liability of Cases and Controls
For a binary trait with population prevalence of $K$ and liability threshold of $t$, the mean and variance of the disease liability for the affected ($a$) and unaffected ($u$) samples can be defined as
\begin{align}
E[P | P>t] = \mu_{pa} &= \frac{z}{K}\notag \\
&= i\\
E[P | P<t] = \mu_{pu} &= -\frac{z}{1-K}\notag \\
&= -\frac{iK}{1-K}\label{eq_meanpu}\\
Var(P|P>t) = \sigma^2_{pa} &= 1-E[P|P>t]^2+E[P|P>t]t\notag \\
&= 1-i^2+it\notag \\
&=1-i(i+t)\\
Var(P|P<t) =\sigma^2_{pu}&=1-E[P|P<t]^2+E[P|P<t]t\notag\\
&=1-\frac{z^2}{(1-K)^2}-\frac{z}{1-K}t\notag\\
&=1-\frac{iK}{1-K}\left(\frac{iK}{1-K}+t\right)\label{eq_varpu}
\end{align}
with $z$ as the height of the standard normal distribution at point $t$.

Using the Pearson-Aiken selection formula[@pearson_mathematical_1903;@aitken_note_1935], we can define the relationship between the moments of the disease liability in the affected and unaffected sample with the corresponding moments of the polygenic risk score as
\begin{align}
\mu_{sa}&= \mu_s+\rho^2\mu_{pa}\\
\mu_{su}&= \mu_s+\rho^2\mu_{pu}\\
\sigma^2_{sa}&=\sigma^2_{s}-(\rho^2)^2(1-\sigma^2_{pa})\notag\\
&=\rho^2\left(1-\rho^2(1-\sigma^2_{pa})\right)\\
\sigma^2_{su}&=\sigma^2_{s}-(\rho^2)^2(1-\sigma^2_{pu})\notag\\
&=\rho^2\left(1-\rho^2(1-\sigma^2_{pu})\right)
\end{align}

If we assume the control samples are randomly sampled from the unaffected population, then $\mu_{pu}$ and $\sigma^2_{pu}$ can be directly calculated based on the population prevalence.
By estimating $\sigma^2_{su}$ from the samples, we can then obtain an estimate of $\rho^2$ using equation (11). As the we don't require any assumption on the distribution of the cases, this should provide an robust estimate of $\rho^2$ even when the cases are biased sampled. 

## Simulation
```{r formula, echo=F}
NagelkerkeR2 <- function (rr) 
{
    n <- nrow(rr$model)
    R2 <- (1 - exp((rr$dev - rr$null)/n))/(1 - exp(-rr$null/n))
    RVAL <- list(N = n, R2 = R2)
    return(RVAL)
}
result_h2l <- function(k, r2n, p) {
    x <- qnorm(1 - k)
    z <- dnorm(x)
    i <- z / k
    cc <- k * (1 - k) * k * (1 - k) / (z^2 * p * (1 - p))
    theta <- i * ((p - k)/(1 - k)) * (i * ((p - k) / ( 1 - k)) - x)
    e <- 1 - p^(2 * p) * (1 - p)^(2 * (1 - p))
    h2l <- cc * e * r2n / (1 + cc * e * theta * r2n)
    return(h2l)
}
```
To access the performance of our method, a simple simulation is performed. 
In this simulation, `r sample.size <- 10000000; sprintf("%i",sample.size)` polygenic risk score is simulated with a random mean and with variance $\sigma^2_s$ range from `r lowerR<-0.01; lowerR` to `r upperR<-0.9; upperR` with stepsize of `r stepR <-0.01; stepR`. 
A phenotype is then generated as
\begin{align}
\epsilon &\sim N(\mu=0, \sigma^2=(1-\sigma^2_s)) \\
P &= S-\bar{S}+\epsilon
\end{align}

Binary trait with prevalence ranged from `r lowerP<-0.01; lowerP` to `r upperP <- 0.35; upperP` with step size `r stepP <- 0.01; stepP` is then generated under the liability model. We then perform three types of sampling:

1. **Normal Sampling:** We uniformly sample `r nselect <- 5000; nselect` cases and controls from the population
2. **Healthy Bias:** We uniformly sample `r nselect` controls from the population and then randomly sample `r nselect` cases from the `r portion.selected <- 0.5; portion.selected` most healthiest affected samples
3. **Berkson's Bias:** We uniformly sample `r nselect` controls from the population and then randomly sample `r nselect` cases from the `r portion.selected <- 0.5; portion.selected` most severely affected samples

The Pearson-Aiken $R^2$ is calculated by solving the quadratic equation 11.
The larger result generated from this quadratic equation are usually larger than 1, thus the smaller result is used as the $R^2$ estimate. 
In addition, as the variance of the polygenic risk score of the controls is a point estimate, there can sometime be no real solution to the equation. 
We use the polyroot method in R which perform the Jenkins-Traub algorithm to calculate the root. 
When there is no real solution, a complex number is provided where we will only use the real part as the $R^2$ estimate.
The Nagelkerke $R^2$ and the Lee adjusted $R^2$ are also calculated to serve as a reference. 

We then repeat the whole procedure `r perm<-10; perm` times to obtain the distribution of the estimates
```{r simulation}
r2 <- seq(lowerR,upperR,stepR)
prevalence <- seq(lowerP,upperP,stepP)
sampling <- c("Normal", "Healthy", "Disease")
poly.mean <- rnorm(1)
simulated.result <- expand.grid(Sampling=sampling, Prevalence=prevalence, R2=r2, Perm=1:perm, MeanSA=NA, MeanSU=NA,VarSA=NA,VarSU=NA, obsR2=NA, leeR2=NA, pearR2a=NA, pearR2b=NA)
for(p in 1:perm)
{
    selectPerm <- simulated.result$Perm %in% p
    for(i in r2)
    {
        score <- rnorm(sample.size, mean=poly.mean, sd=sqrt(i))
        environment <- rnorm(sample.size, mean=0, sd=sqrt(1-i))
        pheno <- (score-poly.mean)+environment
        info <- data.frame(score, pheno)
        info <- info[order(info$pheno),]
        selectR2 <- simulated.result$R2 %in% i & selectPerm
        for(k in prevalence)
        {
            selectK <- selectR2 & simulated.result$Prevalence%in%k
            threshold <- qnorm(k, lower.tail = F)
            info$cc <- as.numeric(info$pheno > threshold)
            case <- info$cc == 1
            control <- !case
            for(s in sampling)
            {
                controls <- sort(sample(which(control), nselect))
                ncase <- sum(case)
                if(s=="Normal")
                {
                    cases <- sort(sample(which(case), nselect))
                }else if(s=="Healthy")
                {
                    cases <- sort(sample(head(which(case), 0.5*ncase), nselect))
                }else if(s=="Disease"){
                    cases <- sort(sample(tail(which(case), 0.5*ncase), nselect))
                }
                obsR2 <- NagelkerkeR2(suppressWarnings(glm(info$cc[c(controls,cases)]~info$score[c(controls,cases)], family=binomial)))$R2
                
                
                selected <- selectK &simulated.result$Sampling %in% s
                simulated.result$MeanSA[selected] <- mean(info$score[cases])
                simulated.result$MeanSU[selected] <- mean(info$score[controls])
                simulated.result$VarSA[selected] <- var(info$score[cases])
                simulated.result$VarSU[selected] <- var(info$score[controls])
                simulated.result$obsR2[selected] <- obsR2
                simulated.result$leeR2[selected] <- result_h2l(k, obsR2, 0.5)
                pearR <-  matrix(c(var(info$score[controls]),-1,1-vtruncnorm(b=qnorm(k,lower.tail=F))), ncol=1) %>%polyroot
                simulated.result$pearR2a[selected] <- pearR[1]
                simulated.result$pearR2b[selected] <- pearR[2]
            }
        }
    }
}

sim.result <- melt(simulated.result[,-c(4:8,12)], id=c("Sampling", "Prevalence","R2"))
sim.result$value <- Re(sim.result$value)
sim.result.sum <- sim.result %>%
    group_by(Sampling, Prevalence, R2, variable)
    summarise(mean=mean(value), sd=sd(value),mse=mean((value-R2)^2))
levels(sim.result$variable) <- c("Observed", "Lee's Adjustment", "PA's Adjustment")
levels(sim.result$Sampling)<- c("Normal", "Healthy Bias", "Berkson's bias")
ggplot(sim.result)+
    geom_abline()+
    theme_bw()+
    geom_point(aes(x=R2, y=mean, color=Prevalence))+
    scale_color_distiller(palette = "Spectral")+
    facet_grid(Sampling~variable)+
    xlab("Empirical R2")+
    ylab("Mean Estimated R2")
ggplot(sim.result)+
    geom_abline()+
    theme_bw()+
    geom_point(aes(x=R2, y=sd, color=Prevalence))+
    scale_color_distiller(palette = "Spectral")+
    facet_grid(Sampling~variable)+
    xlab("Empirical R2")+
    ylab("SD of Estimated R2")
ggplot(sim.result)+
    geom_abline()+
    theme_bw()+
    geom_point(aes(x=R2, y=mse, color=Prevalence))+
    scale_color_distiller(palette = "Spectral")+
    facet_grid(Sampling~variable)+
    xlab("Empirical R2")+
    ylab("MSE Estimated R2")
```

Then for sub-regions (i.e. $R^2 \le 0.3$)

```{r plot subrange}
ggplot(subset(sim.result, R2<=0.3))+
    geom_abline()+
    theme_bw()+
    geom_point(aes(x=R2, y=mean, color=Prevalence))+
    scale_color_distiller(palette = "Spectral")+
    facet_grid(Sampling~variable)+
    xlab("Empirical R2")+
    ylab("Mean Estimated R2")
ggplot(subset(sim.result, R2<=0.3))+
    geom_abline()+
    theme_bw()+
    geom_point(aes(x=R2, y=sd, color=Prevalence))+
    scale_color_distiller(palette = "Spectral")+
    facet_grid(Sampling~variable)+
    xlab("Empirical R2")+
    ylab("SD of Estimated R2")
ggplot(subset(sim.result, R2<=0.3))+
    geom_abline()+
    theme_bw()+
    geom_point(aes(x=R2, y=mse, color=Prevalence))+
    scale_color_distiller(palette = "Spectral")+
    facet_grid(Sampling~variable)+
    xlab("Empirical R2")+
    ylab("MSE Estimated R2")

```


# Reference
